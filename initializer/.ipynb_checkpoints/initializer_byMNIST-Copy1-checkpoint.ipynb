{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0, one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Check MNIST image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11eafaa20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADLlJREFUeJzt3W+IXfWdx/HPJ9pIsBEmW4yjjZuKslDyIIUh+CBIF7W4\nshCLII1PIsSdKt2yhT5YddWNqFiW/qGPClMqiUvXZKGpBqxZNCzYlTUYJZoYTeOWlM4wSbamUo1o\ndea7D+akO41zf/fm3nPvuTPf9wuGufd8z58vh/nMOeeee+/PESEA+SxrugEAzSD8QFKEH0iK8ANJ\nEX4gKcIPJEX4gaQIP5AU4QeSunCQG7PN2wmBPosIdzJfT0d+2zfZPmr7bdv39LIuAIPlbt/bb/sC\nSb+SdKOkSUkvS9ocEUcKy3DkB/psEEf+DZLejohfR8QfJe2UtKmH9QEYoF7Cf4Wk3857PllN+zO2\nx20fsH2gh20BqFnfX/CLiAlJExKn/cAw6eXIPyVpzbznn6+mAVgEegn/y5Kusf0F28slfU3Snnra\nAtBvXZ/2R8Qntv9e0n9IukDS4xHxRm2dAeirrm/1dbUxrvmBvhvIm3wALF6EH0iK8ANJEX4gKcIP\nJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnC\nDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJNX1EN2SZPu4pPckzUj6JCLG6mgKQP/1FP7K\nX0fE72pYD4AB4rQfSKrX8Iek522/Ynu8joYADEavp/0bI2LK9qWSnrP9VkS8MH+G6p8C/xiAIeOI\nqGdF9jZJ70fEdwvz1LMxAC1FhDuZr+vTftsX21559rGkr0g63O36AAxWL6f9qyX93PbZ9fxbROyt\npSsAfVfbaX9HG+O0f+gsW1Y++Vu1alWxfvXVVxfrd91113n3dNbmzZuL9eXLlxfrH330Ucvaww8/\nXFz20UcfLdaHWd9P+wEsboQfSIrwA0kRfiApwg8kRfiBpOr4VB8aNjIy0rJ2xx13FJfdtGlTsX7d\nddd101ItSrfqJOmdd94p1j/44IOWtd27d3fV01LCkR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkuIj\nvUvAxMREy9qdd945wE4+7cMPP2xZO3nyZHHZu+++u1jfu5evj1gIH+kFUET4gaQIP5AU4QeSIvxA\nUoQfSIrwA0nxef5F4Nlnny3Wr7/++q7XPTMzU6y3+wrrQ4cOFeuTk5Mta/v37y8ui/7iyA8kRfiB\npAg/kBThB5Ii/EBShB9IivADSbX9PL/txyX9raRTEbGumrZK0i5JayUdl3RbRPy+7cb4PH9XSvfK\nJenyyy/vet1nzpwp1leuXNn1utGMOj/Pv13STedMu0fSvoi4RtK+6jmARaRt+CPiBUmnz5m8SdKO\n6vEOSbfU3BeAPuv2mn91RExXj09IWl1TPwAGpOf39kdElK7lbY9LGu91OwDq1e2R/6TtUUmqfp9q\nNWNETETEWESMdbktAH3Qbfj3SNpSPd4i6el62gEwKG3Db/tJSf8t6a9sT9reKuk7km60fUzSDdVz\nAItI22v+iNjcotT9h8hxXo4cOVKs93Kff/v27V0vi8WNd/gBSRF+ICnCDyRF+IGkCD+QFOEHkuKr\nuxeBPXv2FOs33HBDy9rs7Gxx2WeeeaarnrD4ceQHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaS4z7/E\ntftq9r179w6oEwwbjvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnC\nDyRF+IGkCD+QVNvw237c9inbh+dN22Z7yvbB6ufm/rYJoG6dHPm3S7ppgek/iIj11c8v6m0LQL+1\nDX9EvCDp9AB6ATBAvVzzf9P269VlwUhtHQEYiG7D/yNJV0laL2la0vdazWh73PYB2we63BaAPugq\n/BFxMiJmImJW0o8lbSjMOxERYxEx1m2TAOrXVfhtj857+lVJh1vNC2A4tf3qbttPSvqypM/ZnpT0\nz5K+bHu9pJB0XNLX+9gjgD5wu+91r3Vj9uA2toRcdtllxfqxY8da1lasWFFcdt26dcX6W2+9Vaxj\n+ESEO5mPd/gBSRF+ICnCDyRF+IGkCD+QFOEHkuJW3xLw7rvvtqxdcsklxWXPnDnTU72dXbt2taw9\n9NBDxWVPn+bzZN3gVh+AIsIPJEX4gaQIP5AU4QeSIvxAUoQfSIr7/EvASy+91LK2YUPLL1lq3NGj\nR4v1e++9t1h/6qmn6mxnyeA+P4Aiwg8kRfiBpAg/kBThB5Ii/EBShB9Iivv8S8CyZa3/hz/22GPF\nZV977bVi/dprry3Wb7311mJ9dHS0WC/ZuXNnsX777bd3ve6ljPv8AIoIP5AU4QeSIvxAUoQfSIrw\nA0kRfiCptvf5ba+R9ISk1ZJC0kRE/ND2Kkm7JK2VdFzSbRHx+zbr4j7/ErNmzZpi/eDBgy1rIyMj\nxWWnpqaK9bVr1xbrMzMzxfpSVed9/k8kfTsivijpWknfsP1FSfdI2hcR10jaVz0HsEi0DX9ETEfE\nq9Xj9yS9KekKSZsk7ahm2yHpln41CaB+53XNb3utpC9J2i9pdURMV6UTmrssALBIXNjpjLY/K+ln\nkr4VEX+w//+yIiKi1fW87XFJ4702CqBeHR35bX9Gc8H/aUTsriaftD1a1UclnVpo2YiYiIixiBir\no2EA9Wgbfs8d4n8i6c2I+P680h5JW6rHWyQ9XX97APqlk1t9GyX9UtIhSbPV5Ps0d93/75KulPQb\nzd3qK46pzK2+fO6///6WtQcffLC47IUXlq9KL7roomL9448/LtaXqk5v9bW95o+I/5LUamXXn09T\nAIYH7/ADkiL8QFKEH0iK8ANJEX4gKcIPJMVXd6MxJ06cKNYvvfTSYp37/Avjq7sBFBF+ICnCDyRF\n+IGkCD+QFOEHkiL8QFIdf40X0I0rr7yyZW3FihUD7ATn4sgPJEX4gaQIP5AU4QeSIvxAUoQfSIrw\nA0lxnx999cADD7SsrVy5srjs9PR0sT47O1uso4wjP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8k1fY+\nv+01kp6QtFpSSJqIiB/a3ibp7yT9bzXrfRHxi341isXpxRdfbFnbunVrcdlHHnmkWJ+ZmemqJ8zp\n5E0+n0j6dkS8anulpFdsP1fVfhAR3+1fewD6pW34I2Ja0nT1+D3bb0q6ot+NAeiv87rmt71W0pck\n7a8mfdP267Yftz3SYplx2wdsH+ipUwC16jj8tj8r6WeSvhURf5D0I0lXSVqvuTOD7y20XERMRMRY\nRIzV0C+AmnQUftuf0VzwfxoRuyUpIk5GxExEzEr6saQN/WsTQN3aht+2Jf1E0psR8f1500fnzfZV\nSYfrbw9Av7Qdotv2Rkm/lHRI0tnPUN4nabPmTvlD0nFJX69eHCytiyG6gT7rdIjutuGvE+EH+q/T\n8PMOPyApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKDHqL7\nd5J+M+/556ppw2hYexvWviR661advf1lpzMO9PP8n9q4fWBYv9tvWHsb1r4keutWU71x2g8kRfiB\npJoO/0TD2y8Z1t6GtS+J3rrVSG+NXvMDaE7TR34ADWkk/LZvsn3U9tu272mih1ZsH7d9yPbBpocY\nq4ZBO2X78Lxpq2w/Z/tY9XvBYdIa6m2b7alq3x20fXNDva2x/Z+2j9h+w/Y/VNMb3XeFvhrZbwM/\n7bd9gaRfSbpR0qSklyVtjogjA22kBdvHJY1FROP3hG1fJ+l9SU9ExLpq2r9IOh0R36n+cY5ExD8O\nSW/bJL3f9MjN1YAyo/NHlpZ0i6Q71OC+K/R1mxrYb00c+TdIejsifh0Rf5S0U9KmBvoYehHxgqTT\n50zeJGlH9XiH5v54Bq5Fb0MhIqYj4tXq8XuSzo4s3ei+K/TViCbCf4Wk3857PqnhGvI7JD1v+xXb\n4003s4DV80ZGOiFpdZPNLKDtyM2DdM7I0kOz77oZ8bpuvOD3aRsjYr2kv5H0jer0dijF3DXbMN2u\n6Wjk5kFZYGTpP2ly33U74nXdmgj/lKQ1855/vpo2FCJiqvp9StLPNXyjD588O0hq9ftUw/38yTCN\n3LzQyNIagn03TCNeNxH+lyVdY/sLtpdL+pqkPQ308Sm2L65eiJHtiyV9RcM3+vAeSVuqx1skPd1g\nL39mWEZubjWytBred0M34nVEDPxH0s2ae8X/fyT9UxM9tOjrKkmvVT9vNN2bpCc1dxr4seZeG9kq\n6S8k7ZN0TNLzklYNUW//qrnRnF/XXNBGG+pto+ZO6V+XdLD6ubnpfVfoq5H9xjv8gKR4wQ9IivAD\nSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFL/B+8NMP+1E2ltAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116ec47b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[100]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = mnist.train.images.shape[1]\n",
    "n_label = 10\n",
    "l1_dim = 256\n",
    "l2_dim = 128\n",
    "l3_dim = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n"
     ]
    }
   ],
   "source": [
    "base = tf.Graph()\n",
    "with base.as_default():\n",
    "    # Input and output placeholder\n",
    "    x = tf.placeholder(tf.float32, shape=[None, image_size], name='x')\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, n_label], name='y_')\n",
    "\n",
    "    # fully connected layer here with ReLU activation\n",
    "    l1 = tf.layers.dense(x, l1_dim, tf.nn.relu)\n",
    "    l2 = tf.layers.dense(l1, l2_dim, tf.nn.relu)\n",
    "    y = tf.layers.dense(l2, l3_dim)\n",
    "\n",
    "    # Mean of the loss using Sigmoid cross-entropy loss\n",
    "    cost = tf.losses.sigmoid_cross_entropy(y_, y)\n",
    "\n",
    "    # Adam optimizer\n",
    "    opt = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using Xavier as an initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n"
     ]
    }
   ],
   "source": [
    "initializer_Xavier = tf.Graph()\n",
    "with initializer_Xavier.as_default():\n",
    "    # Input and output placeholder\n",
    "    x = tf.placeholder(tf.float32, shape=[None, image_size], name='x')\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, n_label], name='y_')\n",
    "\n",
    "    # fully connected layer here with ReLU activation\n",
    "    xavier = tf.contrib.layers.xavier_initializer(uniform=False, seed=None, dtype=tf.float32)\n",
    "    l1 = tf.layers.dense(x, l1_dim, tf.nn.relu, kernel_initializer = xavier)\n",
    "    l2 = tf.layers.dense(l1, l2_dim, tf.nn.relu, kernel_initializer = xavier)\n",
    "    y = tf.layers.dense(l2, l3_dim, kernel_initializer = xavier)\n",
    "\n",
    "    # Mean of the loss using Sigmoid cross-entropy loss\n",
    "    cost = tf.losses.sigmoid_cross_entropy(y_, y)\n",
    "\n",
    "    # Adam optimizer\n",
    "    opt = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### He_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:logits.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:multi_class_labels.dtype=<dtype: 'float32'>.\n",
      "INFO:tensorflow:losses.dtype=<dtype: 'float32'>.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function tensorflow.contrib.keras.python.keras.initializers.he_normal>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initializer_He = tf.Graph()\n",
    "with initializer_He.as_default():\n",
    "    # Input and output placeholder\n",
    "    x = tf.placeholder(tf.float32, shape=[None, image_size], name='x')\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, n_label], name='y_')\n",
    "\n",
    "    # fully connected layer here with ReLU activation\n",
    "    he = tf.contrib.keras.initializers.he_normal()\n",
    "    l1 = tf.layers.dense(x, l1_dim, tf.nn.relu, kernel_initializer = he)\n",
    "    l2 = tf.layers.dense(l1, l2_dim, tf.nn.relu, kernel_initializer = he)\n",
    "    y = tf.layers.dense(l2, l3_dim, kernel_initializer = he)\n",
    "\n",
    "    # Mean of the loss using Sigmoid cross-entropy loss\n",
    "    cost = tf.losses.sigmoid_cross_entropy(y_, y)\n",
    "\n",
    "    # Adam optimizer\n",
    "    opt = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf.contrib.keras.initializers.he_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"x:0\", shape=(?, 784), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Users/shinya/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    941\u001b[0m             subfeed_t = self.graph.as_graph_element(subfeed, allow_tensor=True,\n\u001b[0;32m--> 942\u001b[0;31m                                                     allow_operation=False)\n\u001b[0m\u001b[1;32m    943\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shinya/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2583\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shinya/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   2662\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2663\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2664\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"x:0\", shape=(?, 784), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a2759e12311e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shinya/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shinya/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    943\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: '\n\u001b[0;32m--> 945\u001b[0;31m                             + e.args[0])\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"x:0\", shape=(?, 784), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 50\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "    \n",
    "with tf.Session(graph=base) as sess:\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        sess.run([opt], feed_dict={x: batch[0], y_: batch[1]})\n",
    "\n",
    "        \n",
    "        train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1]})\n",
    "        print('step %d, training accuracy %g' % (e, train_accuracy)) \n",
    "        test_accuracy = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "        print('test accuracy %g' % (test_accuracy))\n",
    "        train_acc.append(train_accuracy)\n",
    "        test_acc.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.24\n",
      "test accuracy 0.1578\n",
      "step 1, training accuracy 0.16\n",
      "test accuracy 0.1726\n",
      "step 2, training accuracy 0.24\n",
      "test accuracy 0.1691\n",
      "step 3, training accuracy 0.14\n",
      "test accuracy 0.1606\n",
      "step 4, training accuracy 0.14\n",
      "test accuracy 0.1598\n",
      "step 5, training accuracy 0.16\n",
      "test accuracy 0.1647\n",
      "step 6, training accuracy 0.2\n",
      "test accuracy 0.1818\n",
      "step 7, training accuracy 0.24\n",
      "test accuracy 0.2059\n",
      "step 8, training accuracy 0.2\n",
      "test accuracy 0.2344\n",
      "step 9, training accuracy 0.26\n",
      "test accuracy 0.2988\n",
      "step 10, training accuracy 0.48\n",
      "test accuracy 0.3837\n",
      "step 11, training accuracy 0.36\n",
      "test accuracy 0.3792\n",
      "step 12, training accuracy 0.4\n",
      "test accuracy 0.3516\n",
      "step 13, training accuracy 0.28\n",
      "test accuracy 0.3525\n",
      "step 14, training accuracy 0.46\n",
      "test accuracy 0.3746\n",
      "step 15, training accuracy 0.48\n",
      "test accuracy 0.3926\n",
      "step 16, training accuracy 0.42\n",
      "test accuracy 0.4373\n",
      "step 17, training accuracy 0.52\n",
      "test accuracy 0.4774\n",
      "step 18, training accuracy 0.46\n",
      "test accuracy 0.5075\n",
      "step 19, training accuracy 0.54\n",
      "test accuracy 0.5425\n",
      "step 20, training accuracy 0.48\n",
      "test accuracy 0.5771\n",
      "step 21, training accuracy 0.62\n",
      "test accuracy 0.6245\n",
      "step 22, training accuracy 0.72\n",
      "test accuracy 0.6704\n",
      "step 23, training accuracy 0.74\n",
      "test accuracy 0.7122\n",
      "step 24, training accuracy 0.78\n",
      "test accuracy 0.7419\n",
      "step 25, training accuracy 0.84\n",
      "test accuracy 0.7486\n",
      "step 26, training accuracy 0.82\n",
      "test accuracy 0.7417\n",
      "step 27, training accuracy 0.76\n",
      "test accuracy 0.7362\n",
      "step 28, training accuracy 0.74\n",
      "test accuracy 0.7331\n",
      "step 29, training accuracy 0.74\n",
      "test accuracy 0.7312\n",
      "step 30, training accuracy 0.82\n",
      "test accuracy 0.7307\n",
      "step 31, training accuracy 0.72\n",
      "test accuracy 0.739\n",
      "step 32, training accuracy 0.82\n",
      "test accuracy 0.7534\n",
      "step 33, training accuracy 0.74\n",
      "test accuracy 0.7733\n",
      "step 34, training accuracy 0.7\n",
      "test accuracy 0.7895\n",
      "step 35, training accuracy 0.78\n",
      "test accuracy 0.8004\n",
      "step 36, training accuracy 0.78\n",
      "test accuracy 0.8018\n",
      "step 37, training accuracy 0.82\n",
      "test accuracy 0.7976\n",
      "step 38, training accuracy 0.84\n",
      "test accuracy 0.7926\n",
      "step 39, training accuracy 0.86\n",
      "test accuracy 0.7859\n",
      "step 40, training accuracy 0.76\n",
      "test accuracy 0.7777\n",
      "step 41, training accuracy 0.8\n",
      "test accuracy 0.7742\n",
      "step 42, training accuracy 0.86\n",
      "test accuracy 0.773\n",
      "step 43, training accuracy 0.76\n",
      "test accuracy 0.7816\n",
      "step 44, training accuracy 0.82\n",
      "test accuracy 0.8005\n",
      "step 45, training accuracy 0.8\n",
      "test accuracy 0.8206\n",
      "step 46, training accuracy 0.8\n",
      "test accuracy 0.8369\n",
      "step 47, training accuracy 0.9\n",
      "test accuracy 0.8427\n",
      "step 48, training accuracy 0.92\n",
      "test accuracy 0.8423\n",
      "step 49, training accuracy 0.88\n",
      "test accuracy 0.8384\n",
      "step 50, training accuracy 0.88\n",
      "test accuracy 0.8306\n",
      "step 51, training accuracy 0.8\n",
      "test accuracy 0.8293\n",
      "step 52, training accuracy 0.8\n",
      "test accuracy 0.8344\n",
      "step 53, training accuracy 0.78\n",
      "test accuracy 0.8457\n",
      "step 54, training accuracy 0.82\n",
      "test accuracy 0.8533\n",
      "step 55, training accuracy 0.8\n",
      "test accuracy 0.8542\n",
      "step 56, training accuracy 0.78\n",
      "test accuracy 0.8499\n",
      "step 57, training accuracy 0.88\n",
      "test accuracy 0.8426\n",
      "step 58, training accuracy 0.8\n",
      "test accuracy 0.8393\n",
      "step 59, training accuracy 0.86\n",
      "test accuracy 0.8404\n",
      "step 60, training accuracy 0.92\n",
      "test accuracy 0.8401\n",
      "step 61, training accuracy 0.86\n",
      "test accuracy 0.8397\n",
      "step 62, training accuracy 0.96\n",
      "test accuracy 0.8377\n",
      "step 63, training accuracy 0.92\n",
      "test accuracy 0.8363\n",
      "step 64, training accuracy 0.8\n",
      "test accuracy 0.8403\n",
      "step 65, training accuracy 0.82\n",
      "test accuracy 0.8508\n",
      "step 66, training accuracy 0.92\n",
      "test accuracy 0.8582\n",
      "step 67, training accuracy 0.88\n",
      "test accuracy 0.8624\n",
      "step 68, training accuracy 0.84\n",
      "test accuracy 0.8639\n",
      "step 69, training accuracy 0.88\n",
      "test accuracy 0.8673\n",
      "step 70, training accuracy 0.86\n",
      "test accuracy 0.8659\n",
      "step 71, training accuracy 0.9\n",
      "test accuracy 0.8677\n",
      "step 72, training accuracy 0.88\n",
      "test accuracy 0.871\n",
      "step 73, training accuracy 0.84\n",
      "test accuracy 0.8741\n",
      "step 74, training accuracy 0.9\n",
      "test accuracy 0.8761\n",
      "step 75, training accuracy 0.78\n",
      "test accuracy 0.8758\n",
      "step 76, training accuracy 0.76\n",
      "test accuracy 0.8772\n",
      "step 77, training accuracy 0.9\n",
      "test accuracy 0.8756\n",
      "step 78, training accuracy 0.94\n",
      "test accuracy 0.876\n",
      "step 79, training accuracy 0.92\n",
      "test accuracy 0.8758\n",
      "step 80, training accuracy 0.82\n",
      "test accuracy 0.8757\n",
      "step 81, training accuracy 0.86\n",
      "test accuracy 0.878\n",
      "step 82, training accuracy 0.84\n",
      "test accuracy 0.8786\n",
      "step 83, training accuracy 0.78\n",
      "test accuracy 0.8815\n",
      "step 84, training accuracy 0.86\n",
      "test accuracy 0.8826\n",
      "step 85, training accuracy 0.8\n",
      "test accuracy 0.883\n",
      "step 86, training accuracy 0.8\n",
      "test accuracy 0.8841\n",
      "step 87, training accuracy 0.82\n",
      "test accuracy 0.885\n",
      "step 88, training accuracy 0.9\n",
      "test accuracy 0.8842\n",
      "step 89, training accuracy 0.88\n",
      "test accuracy 0.8836\n",
      "step 90, training accuracy 0.9\n",
      "test accuracy 0.8839\n",
      "step 91, training accuracy 0.86\n",
      "test accuracy 0.8859\n",
      "step 92, training accuracy 0.92\n",
      "test accuracy 0.8868\n",
      "step 93, training accuracy 0.88\n",
      "test accuracy 0.8891\n",
      "step 94, training accuracy 0.96\n",
      "test accuracy 0.8897\n",
      "step 95, training accuracy 0.96\n",
      "test accuracy 0.8903\n",
      "step 96, training accuracy 0.88\n",
      "test accuracy 0.8885\n",
      "step 97, training accuracy 0.96\n",
      "test accuracy 0.8845\n",
      "step 98, training accuracy 0.84\n",
      "test accuracy 0.8838\n",
      "step 99, training accuracy 0.92\n",
      "test accuracy 0.883\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "with tf.Session(graph=initializer_Xavier) as sess:\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        sess.run([opt], feed_dict={x: batch[0], y_: batch[1]})\n",
    "\n",
    "        \n",
    "        train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1]})\n",
    "        print('step %d, training accuracy %g' % (e, train_accuracy)) \n",
    "        test_accuracy = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "        print('test accuracy %g' % (test_accuracy))\n",
    "        train_acc.append(train_accuracy)\n",
    "        test_acc.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.02\n",
      "test accuracy 0.079\n",
      "step 1, training accuracy 0.06\n",
      "test accuracy 0.0727\n",
      "step 2, training accuracy 0.04\n",
      "test accuracy 0.1068\n",
      "step 3, training accuracy 0.2\n",
      "test accuracy 0.1317\n",
      "step 4, training accuracy 0.12\n",
      "test accuracy 0.1492\n",
      "step 5, training accuracy 0.12\n",
      "test accuracy 0.1712\n",
      "step 6, training accuracy 0.22\n",
      "test accuracy 0.1886\n",
      "step 7, training accuracy 0.34\n",
      "test accuracy 0.2046\n",
      "step 8, training accuracy 0.34\n",
      "test accuracy 0.2319\n",
      "step 9, training accuracy 0.3\n",
      "test accuracy 0.2615\n",
      "step 10, training accuracy 0.42\n",
      "test accuracy 0.2696\n",
      "step 11, training accuracy 0.28\n",
      "test accuracy 0.2835\n",
      "step 12, training accuracy 0.36\n",
      "test accuracy 0.2946\n",
      "step 13, training accuracy 0.38\n",
      "test accuracy 0.3055\n",
      "step 14, training accuracy 0.42\n",
      "test accuracy 0.3075\n",
      "step 15, training accuracy 0.46\n",
      "test accuracy 0.3211\n",
      "step 16, training accuracy 0.44\n",
      "test accuracy 0.3516\n",
      "step 17, training accuracy 0.46\n",
      "test accuracy 0.4055\n",
      "step 18, training accuracy 0.48\n",
      "test accuracy 0.49\n",
      "step 19, training accuracy 0.62\n",
      "test accuracy 0.5726\n",
      "step 20, training accuracy 0.68\n",
      "test accuracy 0.6363\n",
      "step 21, training accuracy 0.68\n",
      "test accuracy 0.6892\n",
      "step 22, training accuracy 0.66\n",
      "test accuracy 0.7239\n",
      "step 23, training accuracy 0.6\n",
      "test accuracy 0.7535\n",
      "step 24, training accuracy 0.78\n",
      "test accuracy 0.7729\n",
      "step 25, training accuracy 0.8\n",
      "test accuracy 0.7786\n",
      "step 26, training accuracy 0.8\n",
      "test accuracy 0.7787\n",
      "step 27, training accuracy 0.78\n",
      "test accuracy 0.766\n",
      "step 28, training accuracy 0.88\n",
      "test accuracy 0.7368\n",
      "step 29, training accuracy 0.82\n",
      "test accuracy 0.7095\n",
      "step 30, training accuracy 0.82\n",
      "test accuracy 0.6837\n",
      "step 31, training accuracy 0.66\n",
      "test accuracy 0.67\n",
      "step 32, training accuracy 0.64\n",
      "test accuracy 0.6689\n",
      "step 33, training accuracy 0.7\n",
      "test accuracy 0.6765\n",
      "step 34, training accuracy 0.72\n",
      "test accuracy 0.6976\n",
      "step 35, training accuracy 0.76\n",
      "test accuracy 0.7283\n",
      "step 36, training accuracy 0.78\n",
      "test accuracy 0.753\n",
      "step 37, training accuracy 0.9\n",
      "test accuracy 0.7706\n",
      "step 38, training accuracy 0.82\n",
      "test accuracy 0.7849\n",
      "step 39, training accuracy 0.86\n",
      "test accuracy 0.7938\n",
      "step 40, training accuracy 0.88\n",
      "test accuracy 0.797\n",
      "step 41, training accuracy 0.68\n",
      "test accuracy 0.8006\n",
      "step 42, training accuracy 0.76\n",
      "test accuracy 0.8073\n",
      "step 43, training accuracy 0.88\n",
      "test accuracy 0.8152\n",
      "step 44, training accuracy 0.82\n",
      "test accuracy 0.8261\n",
      "step 45, training accuracy 0.9\n",
      "test accuracy 0.829\n",
      "step 46, training accuracy 0.82\n",
      "test accuracy 0.8284\n",
      "step 47, training accuracy 0.82\n",
      "test accuracy 0.8318\n",
      "step 48, training accuracy 0.8\n",
      "test accuracy 0.8403\n",
      "step 49, training accuracy 0.88\n",
      "test accuracy 0.8435\n",
      "step 50, training accuracy 0.74\n",
      "test accuracy 0.8474\n",
      "step 51, training accuracy 0.78\n",
      "test accuracy 0.8465\n",
      "step 52, training accuracy 0.84\n",
      "test accuracy 0.8413\n",
      "step 53, training accuracy 0.9\n",
      "test accuracy 0.831\n",
      "step 54, training accuracy 0.8\n",
      "test accuracy 0.821\n",
      "step 55, training accuracy 0.8\n",
      "test accuracy 0.8202\n",
      "step 56, training accuracy 0.84\n",
      "test accuracy 0.8265\n",
      "step 57, training accuracy 0.84\n",
      "test accuracy 0.8332\n",
      "step 58, training accuracy 0.94\n",
      "test accuracy 0.8402\n",
      "step 59, training accuracy 0.86\n",
      "test accuracy 0.8392\n",
      "step 60, training accuracy 0.88\n",
      "test accuracy 0.8382\n",
      "step 61, training accuracy 0.9\n",
      "test accuracy 0.8361\n",
      "step 62, training accuracy 0.92\n",
      "test accuracy 0.8361\n",
      "step 63, training accuracy 0.78\n",
      "test accuracy 0.8451\n",
      "step 64, training accuracy 0.82\n",
      "test accuracy 0.853\n",
      "step 65, training accuracy 0.9\n",
      "test accuracy 0.8611\n",
      "step 66, training accuracy 0.88\n",
      "test accuracy 0.8628\n",
      "step 67, training accuracy 0.9\n",
      "test accuracy 0.8624\n",
      "step 68, training accuracy 0.9\n",
      "test accuracy 0.8581\n",
      "step 69, training accuracy 0.88\n",
      "test accuracy 0.8549\n",
      "step 70, training accuracy 0.92\n",
      "test accuracy 0.8542\n",
      "step 71, training accuracy 0.84\n",
      "test accuracy 0.8543\n",
      "step 72, training accuracy 0.92\n",
      "test accuracy 0.8572\n",
      "step 73, training accuracy 0.9\n",
      "test accuracy 0.8635\n",
      "step 74, training accuracy 0.86\n",
      "test accuracy 0.8704\n",
      "step 75, training accuracy 0.8\n",
      "test accuracy 0.8737\n",
      "step 76, training accuracy 0.82\n",
      "test accuracy 0.8741\n",
      "step 77, training accuracy 0.86\n",
      "test accuracy 0.8707\n",
      "step 78, training accuracy 0.8\n",
      "test accuracy 0.8695\n",
      "step 79, training accuracy 0.8\n",
      "test accuracy 0.8702\n",
      "step 80, training accuracy 0.86\n",
      "test accuracy 0.8759\n",
      "step 81, training accuracy 0.92\n",
      "test accuracy 0.8812\n",
      "step 82, training accuracy 0.86\n",
      "test accuracy 0.8847\n",
      "step 83, training accuracy 0.82\n",
      "test accuracy 0.8843\n",
      "step 84, training accuracy 0.96\n",
      "test accuracy 0.883\n",
      "step 85, training accuracy 0.86\n",
      "test accuracy 0.8822\n",
      "step 86, training accuracy 0.82\n",
      "test accuracy 0.8827\n",
      "step 87, training accuracy 0.88\n",
      "test accuracy 0.8858\n",
      "step 88, training accuracy 0.92\n",
      "test accuracy 0.8874\n",
      "step 89, training accuracy 0.94\n",
      "test accuracy 0.8873\n",
      "step 90, training accuracy 0.94\n",
      "test accuracy 0.89\n",
      "step 91, training accuracy 0.88\n",
      "test accuracy 0.8916\n",
      "step 92, training accuracy 0.9\n",
      "test accuracy 0.8902\n",
      "step 93, training accuracy 0.84\n",
      "test accuracy 0.8875\n",
      "step 94, training accuracy 0.88\n",
      "test accuracy 0.8847\n",
      "step 95, training accuracy 0.88\n",
      "test accuracy 0.8838\n",
      "step 96, training accuracy 0.88\n",
      "test accuracy 0.8831\n",
      "step 97, training accuracy 0.78\n",
      "test accuracy 0.8865\n",
      "step 98, training accuracy 0.92\n",
      "test accuracy 0.8873\n",
      "step 99, training accuracy 0.82\n",
      "test accuracy 0.8897\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 50\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "    \n",
    "with tf.Session(graph=initializer_He) as sess:\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        sess.run([opt], feed_dict={x: batch[0], y_: batch[1]})\n",
    "\n",
    "        \n",
    "        train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1]})\n",
    "        print('step %d, training accuracy %g' % (e, train_accuracy)) \n",
    "        test_accuracy = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "        print('test accuracy %g' % (test_accuracy))\n",
    "        train_acc.append(train_accuracy)\n",
    "        test_acc.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(x, y_):\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        sess.run([opt], feed_dict={x: batch[0], y_: batch[1]})\n",
    "\n",
    "        \n",
    "        train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1]})\n",
    "        print('step %d, training accuracy %g' % (e, train_accuracy)) \n",
    "        test_accuracy = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "        print('test accuracy %g' % (test_accuracy))\n",
    "        train_acc.append(train_accuracy)\n",
    "        test_acc.append(test_accuracy)\n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
